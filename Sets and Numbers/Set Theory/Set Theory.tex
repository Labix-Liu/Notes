\documentclass[a4paper]{article}

\input{C:/Users/liula/Desktop/Latex/Headers/Headers.tex}

\pagestyle{fancy}
\fancyhf{}
\rhead{Labix}
\lhead{Set Theory}
\rfoot{\thepage}

\title{Set Theory}

\author{Labix}

\date{\today}
\begin{document}
\maketitle
\begin{abstract}
These notes aim to develop basic notions of sets and logics following closely to ZFC set theory, as well as introducing a few examples and provide proofs for theorems that require careful inspection. Theorems that with proofs ommitted are expected to have readers be able to prove them. Although that there is a wide variety of axiomatic set theories that are accepted by different mathematicians, ZFC set theory is considered to be one of the most widely recognized theories among them all. \\

Beware that while set theory has no formal prequisites in terms of its content (except perhaps logic theory), the mathematical concepts are not at all easy to understand. In fact the more foundational the mathematics, the harder the proofs and the more abstract the content becomes. First year university students should aim to complete up to chapter $3$ in order to develop the suitable language for further mathematical content in their degrees. \\

Famous mathematicians who contributed to this area in mathematics include Ernst Zermelo and Abraham Fraenkel, Kurt GÃ¶del and Georg Cantor and many more. \\
\textbf{References}
\begin{itemize}
\item Naive Set Theory by Paul R. Halmos
\end{itemize}
\end{abstract}
\pagebreak
\tableofcontents

\pagebreak
\section{Basic Logic}
\subsection{Logical Symbols}
\begin{defn}{Quantifiers}{}\\
The following symbols are called quantifiers. 
\begin{itemize}
\item ``$\forall$'' is the quantifier interpreted as ``for all''. 
\item ``$\exists$'' is the quantifier interpreted as ``there exists''. 
\end{itemize}
\end{defn}

\begin{defn}{Equality Symbol}{}
\end{defn}

\subsection{Logical Connectives}
\begin{defn}{Arguments}{}\\
An argument consists of a premise and a conclusion. (Our conclusions are binary and outputs only either ``True'' (T) or ``False'' (F). )
\end{defn}

\begin{defn}{Logical Connectives}{}\\
A logical connective takes inputs as arguments and outputs an argument. 
\end{defn}

\begin{defn}{Negation}{}\\
The negation symbol ``$\neg$'' is the quantifier interpreted as ``not''. It is a logical connective on one logical value. The truth table is given by 
\begin{center}
\begin{tabular}{c|c}
$P$ & $\neg P$ \\ \hline
$F$ & T        \\
T   & F       
\end{tabular}
\end{center}
for an argument $P$. 
\end{defn}

\begin{defn}{Disjunction}{}\\
The disjunction symbol ``$\vee$'' is the quantifier interpreted as ``or''. It is a logical connective on two logical values. The truth table is given by 
\begin{center}
\begin{tabular}{c|c|c}
$P$ & $Q$ & $P\vee Q$ \\ \hline
F   & F   & F        \\
F   & T   & T        \\
T   & F   & T        \\
T   & T   & T       
\end{tabular}
\end{center}
for two arguments $P$ and $Q$. 
\end{defn}

\begin{defn}{Conjunction}{}\\
The conjunction symbol ``$\wedge$'' is the quantifier interpreted as ``and''. It is a logical connective on two logical values. The truth table is given by 
\begin{center}
\begin{tabular}{c|c|c}
$P$ & $Q$ & $P\wedge Q$ \\ \hline
F   & F   & F        \\
F   & T   & F        \\
T   & F   & F        \\
T   & T   & T       
\end{tabular}
\end{center}
for two arguments $P$ and $Q$. 
\end{defn}

\begin{defn}{Conditional}{}\\
The conditional symbol ``$\to$'' is the quantifier interpreted as ``implies''. It is a logical connective on two logical values. The truth table is given by 
\begin{center}
\begin{tabular}{c|c|c}
$P$ & $Q$ & $P\to Q$ \\ \hline
F   & F   & T        \\
F   & T   & T        \\
T   & F   & F        \\
T   & T   & T       
\end{tabular}
\end{center}
for two arguments $P$ and $Q$. 
\end{defn}

\begin{defn}{Biconditional}{}\\
The biconditional symbol ``$\iff$'' is the quantifier interpreted as ``if and only if''. It is a logical connective on two logical values. The truth table is given by 
\begin{center}
\begin{tabular}{c|c|c}
$P$ & $Q$ & $P\iff Q$ \\ \hline
F   & F   & T        \\
F   & T   & F        \\
T   & F   & F        \\
T   & T   & T       
\end{tabular}
\end{center}
for two arguments $P$ and $Q$. 
\end{defn}

\pagebreak
\section{Introduction to Sets}
\subsection{Logical Symbols for Sets}
For the purposes of set theory as a language for describing mathematical objects, it is sufficient to only learn about Naive Set Theory, in which one cares less about the foundations of set theory axiomatically. Under this assumption, we take the definition of a set to be a list of objects. Formally speaking, we have the following. 

\begin{defn}{The Language of Set Theory}{}\\
The language of set theory is a first order logic that includes the following. 
\begin{itemize}
\item An equality symbol. 
\item A non-logical symbol ``$\in$'' interpreted as ``membership''. 
\end{itemize}
We call its variables ``sets''. 
\end{defn}

The intuitive meaning of a set comes from the concept of belonging. In such a formal definition, all variables are sets. To distinguish the conceptual difference of sets and members of a set, we make use of the word variable to emphasize the role of the variable as a membership of a certain set, rather than being a set itself. 

\begin{defn}{The Not Membership Symbol}{}\\
Define the non-logical symbol ``$\notin$'' by $x\notin A$ if and only if $\neg (x\in A)$. 
\end{defn}

\subsection{Constructing a Set}
\begin{axm}{The Axiom of Specification}{}\\
Let $A$ be a set. Let $\varphi$ be a formula. Then there exists a set $B$ such that $x\in B$ if and only if $x\in A$ and $\varphi(x)$. In first order logic symbols, we have $$\forall A\exists B\forall x(x\in B\leftrightarrow(x\in A\wedge\varphi(x)))$$
\end{axm}

\begin{defn}{Set Builder Notation}{} Let $A$ be a set. Let $\varphi$ be a formula. Define the unique set in which a variable $x\in B$ if and only if $x\in A$ and $\varphi(x)$ to be $$\{x\in A\;|\;\varphi(x)\}$$
\end{defn}

\begin{prp}{}{}\\
There exists a unique set $\emptyset$ such that for all variables $x$, $x\notin\emptyset$. 
\end{prp}

\begin{defn}{The Empty Set}{}\\
Define the empty set $\emptyset$ to be the unique set such that $x\notin\emptyset$ for all sets $x$. 
\end{defn}

\begin{axm}{The Axiom of Replacement}{}
\end{axm}

\subsection{Subsets and Equality}
Whenever presented an axiom, the reader should be prompt automatically to think about the reason for introducing this axiom. Could it be formulated in another way? Could it not be an axiom? 

\begin{axm}{The Axiom of Extensionality}{}\\
Let $A,B$ be sets. Then $A$ and $B$ are equal if for any variable $x$, $x\in A$ if and only if $x\in B$. In first order logic symbols, we have $$\forall A\forall B(A=B\leftrightarrow\forall t(t\in A\leftrightarrow t\in B))$$ In this case, we write $A=B$. 
\end{axm}

\begin{defn}{Subsets}{}\\
Let $A,B$ be sets. 
\begin{itemize}
\item We say that $A\subseteq B$ if $x\in A\implies x\in B$. 
\item We say that $A\subset B$ if $x\in A\implies x\in B$ and $\exists b\in B,b\notin A$. 
\end{itemize}
\end{defn}

\begin{prp}{}{}\\
Let $A,B$ be sets. Then we have $$A=B\iff A\subseteq B\;\;\text{ and }\;\; B\subseteq A$$
\end{prp}

\begin{lmm}{}{}\\
Let $A,B,C$ be sets. Then the following are true. 
\begin{itemize}
\item $\emptyset\subseteq A$. 
\item $A\subseteq A$. 
\item $A\subseteq B$ and $B\subseteq C$ implies $A\subseteq C$. 
\end{itemize}
\end{lmm}
\subsection{Paradoxes and its Resolution}
The Axiom of regularity, similar to the axiom schema of specification in the next chapter is meant to prevent paradoxes rather than construct new sets. 

\begin{axm}{The Axiom of Regularity}{} Every non-empty set $X$ contains an element $y\in X$ such that $X$ and $y$ are disjoint sets. 
\end{axm}

With this axiom, expressions such as $S\in S$ does not make sense anymore. Which is good, because it prevents self referencing as a potential paradox. 

\pagebreak
\section{Operations on Sets}
\subsection{Ordered Pairs}
\begin{axm}{The Axiom of Pairing}{}\\
For any variables $a,b$, there exists a set $C$ such that for any variable $x$, $x\in C$ if and only if $x=a$ or $x=b$. In first order logic, we have $$\forall a\forall b\exists C\forall x(x\in C\leftrightarrow(x=a\vee x=b))$$ In this case we denote $C$ by $\{a,b\}$. 
\end{axm}

\begin{defn}{Ordered Pairs}{}\\
Let $a,b$ be variables. Define $(a,b)=\{a,\{a,b\}\}$. 
\end{defn}

\begin{prp}{}{} Let $(a,b)$ and $(c,d)$ be ordered pairs. Then $(a,b)=(c,d)$ if and only if $a=c$ and $b=d$. 
\begin{proof} Suppose that $(a,b)=(c,d)$. Then we have by definition, $$\{\{a\},\{a,b\}\}=\{\{c\},\{c,d\}\}$$ There are two cases: $a=b$ and $a\neq b$. Suppose that $a=b$, then $\{\{a\}\}=\{\{c\},\{c,d\}\}$. This forces $\{a\}=\{c\}=\{c,d\}$ and $a=c=d$. Suppose that $a\neq b$. Then $\{a\}=\{c\}$ and $\{a,b\}=\{c,d\}$. Thus $a=c$ and $b=d$. $b$ cannot be $c$ here since $a=b=c$ is a contradiction. \\

Now suppose that $a=c$ and $b=d$, then $\{a\}=\{c\}$ and $\{a,b\}=\{c,d\}$ thus $\{\{a\},\{a,b\}\}=\{\{c\},\{c,d\}\}$. 
\end{proof}
\end{prp}

\subsection{Unions and Intersections}
\begin{axm}{The Axiom of Union}{}\\
For any set $A$, there exists a set $B$ such that for any set $x$, $x\in B$ if and only if there exists a set $y\in A$ such that $x\in y$. In first order logic symbols, we have $$\forall A\exists B\forall x(x\in B\leftrightarrow\exists y(x\in y\wedge y\in A))$$
\end{axm}

One must wonder: why go the long away round and say that a unions are elements of a set living in a set of sets? Essentially this allows us to proceed with the The Axiom of Pairing. The Axiom of pairing allows new sets to be created from old sets. And in fact, the The Axiom of Unions is simply recovering the elements hidden from the sets given by the axiom of pairing. 

\begin{defn}{Union of Sets}{} Let $\mF$ be a set. Define the union of sets in $\mF$ to be $$\bigcup_{A\in\mF}A=\{x\in B\;|\;\exists y(x\in y\vee y\in B)\}$$ where $B$ is the set defined by the axiom of union applied to $\mF$. 
\end{defn}

At this point the reader should not be confused between operations and statements. I assume the readers are crystal clear about it but I would elaborate on it as a reminder. Unions and the upcoming intersections are operations on sets that produce new sets. They are by no means able to be evaluated to be true or false. This property is preserved exclusively for statements and statements alone. And statements are given by symbols such as $=$ and $\subseteq$. If you think about it, one should be able to judge whether $A\subseteq B$ is true or false, depending on the contents of $A$ and $B$ while it does not make sense to judge the validity of $A\cup B$. 

\begin{lmm}{}{}\\
Let $A,B,C$ be sets. Then the following are true. 
\begin{itemize}
\item Identity: $A\cup\emptyset=A$
\item Commutativity: $A\cup B=B\cup A$
\item Associativity: $(A\cup B)\cup C=A\cup(B\cup C)$
\item Idempotent: $A\cup A=A$
\item $A\subset B\iff A\cup B=B$
\end{itemize}
\begin{proof} We prove it in order. 
\begin{itemize}
\item $A\cup\emptyset=\{x:x\in A\text{ or }x\in\emptyset\}=\{x:x\in A\}=A$
\item $A\cup B=\{x:x\in A\text{ or }x\in B\}=\{x:x\in B\text{ or }x\in A\}=B\cup A$
\item Proved similarly by expanding the definition of union and using the fact that the logic operator "or" is commutative. 
\item $A\cup A=\{x:x\in A\text{ or }x\in A\}=\{x:x\in A\}=A$
\item Suppose that $A\subset B$. $x\in A\cup B\implies x\in A$ or $x\in B\implies x\in B$ or $x\in B\implies x\in B$. Thus $A\cup B\subset B$. $x\in B\implies x\in B$ or $x\in B\implies x\in A$ or $x\in B\implies x\in A\cup B$. Thus $B\subset A\cup B$. Now suppose that $A\cup B=B$. $x\in A\implies x\in B$ thus $A\subset B$. 
\end{itemize}
\end{proof}
\end{lmm}

There is a bunch of fancy names in front of the properties of the operations. They are simply jargons for the properties of any operations in general. Do not be frightened by it since I will mostly like not recall properties from their fancy names unless I want to shortent the length of a proof. \linebreak\linebreak
We are shown an operation which is some what equivalent to the "or" operation in logic theory. We shall present a similar notion for "and" as well. 

\begin{prp}{}{}\\
Let $\mF$ be a set. There exists a unique set $S$ such that for any variable $x$, $x\in S$ if and only if $x\in A$ for all $A\in\mF$. 
\end{prp}

\begin{defn}{Intersection of Sets}{}\\
Let $\mF$ be a set. Define the intersection of sets of $\mF$ to be the unique set $$\bigcap_{A\in\mF}A$$ such that $x\in\bigcap_{A\in\mF}A$ if and only if $x\in A$ for all $A\in\mF$. 
\end{defn}

The intersection is a another way to produce new sets from old, except that smaller sets are created, instead of larger sets. However this does not mean that the number of sets it procures is limited. 

\begin{lmm}{}{} Let $A,B,C$ be sets. 
\begin{itemize}
\item Identity: $A\cap\emptyset=\emptyset$
\item Commutativity: $A\cap B=B\cap A$
\item Associativity: $(A\cap B)\cap C=A\cap(B\cap C)$
\item Idempotent: $A\cap A=A$
\item $A\subseteq B\iff A\cap B=A$
\end{itemize}
\begin{proof} The first four are proved in similarity to the counterpart with unions. We prove the last item. Suppose that $A\subset B$. $x\in A\cap B\implies x\in A$ and $x\in B$. Thus $x\in A$ and $A\cap B\subset A$. $x\in A\implies x\in A$ and $x\in A\implies x\in A$ and $x\in B$. Thus $x\in A\cap B$ and $A\subset A\cap B$. Now suppose that $A\cap B=A$. $x\in A\implies x\in A\cap B\implies x\in B$. Thus $A\subset B$. 
\end{proof}
\end{lmm}

Finally we have the distributive law that links the two operators between sets. 

\begin{prp}{Distributive Law}{} Let $A,B,C$ be sets. 
\begin{itemize}
\item $A\cap(B\cup C)=(A\cap B)\cup(A\cap C)$
\item $A\cup(B\cap C)=(A\cup B)\cap(A\cup C)$
\end{itemize}
\begin{proof} The two are proved by supposing $x$ in the left and the right and proving that the left and the right are subsets of each other by logic. 
\end{proof}
\end{prp}

\begin{defn}{Disjoint Sets}{}\\
Let $A,B$ be sets. We say that $A$ and $B$ are disjoint if and only if $A\cap B=\emptyset$. 
\end{defn}

\subsection{Set Complements}
Another important concept in set theory is complements of sets. However one shall see that there are exactly two notions of complements. One that involves complements from the universe and another complement from a relative set. 

\begin{defn}{Set Complements}{} Let $A,B$ be sets. Define $$A\setminus B=\{x\in A\;|\;x\notin B\}$$ to be the relative complement of $B$ in $A$. 
\end{defn}

\begin{lmm}{}{} Let $E$ be a set. Let $A,B\subseteq E$ be subsets. Then the following are true. 
\begin{itemize}
\item $(E\setminus A)\setminus A=A$. 
\item $E\setminus\emptyset=E$. 
\item $E\setminus E=\emptyset$. 
\item $A\cap E\setminus A=\emptyset$. 
\item $A\cup E\setminus A=E$. 
\item $A\subseteq B$ if and only if $E\setminus B\subseteq E\setminus A$. 
\end{itemize}
\begin{proof} The four are proved by expanding on the definition of complement and proved by logic. 
\end{proof}
\end{lmm}

Similar to the distributive law, we can associate the complement operator with the previous two operators, namely union and intersection. 

\begin{prp}{De Morgans Laws}{}\\
Let $E$ be a set. Let $A,B\subseteq E$ be subsets. Then the following are true. 
\begin{itemize}
\item $E\setminus(A\cup B)=E\setminus A\cap E\setminus B$. 
\item $E\setminus(A\cap B)=E\setminus A\cup E\setminus B$. 
\end{itemize}
\end{prp}

\begin{lmm}{}{} Let $E$ be a set. Let $A,B\subseteq E$ be subsets. Then the following are true. 
\begin{itemize}
\item $A\subseteq B$ if and only if $A\setminus B=\emptyset$. 
\item $A\setminus(A\setminus B)=A\cap B$. 
\end{itemize}
\begin{proof} The four are proved by expanding on the definition of complement and proved by logic. 
\end{proof}
\end{lmm}

\subsection{The Axiom of Powers}
Finally, the axiom of power is simple: to assert the existence of power sets of a set. 

\begin{axm}{The Axiom of Power Set}{} For each set there exists a collection of sets that contains among its elements all the subsets of the given set. Define that collection to be $\mathcal{P}(A)$, where $A$ is any set. 
\end{axm}

The following is a proposition regarding integrating the operation of taking power sets and unions and intersections. It serves as a good exercise. 

\begin{prp}{}{} Let $E$ be a collection of sets. Then the following are true. 
\begin{itemize}
\item $\bigcap_{X\in E}\mathcal{P}(X)=\mathcal{P}(\bigcap_{X\in E}X)$
\item $\bigcup_{X\in E}\mathcal{P}(X)\subseteq\mathcal{P}(\bigcup_{X\in E}X)$
\end{itemize}
\begin{proof}
Let $A\in\bigcap_{X\in E}\mathcal{P}(X)$. Then $A\subseteq X$ for all $X\in E$. Thus $A\subseteq\bigcap_{X\in E}X$ and $A\in\mathcal{P}(\bigcap_{X\in E}X)$. For the reverse inclusion, the above implications are all double sided thus we are done. \\
Let $A\in\bigcup_{X\in E}\mathcal{P}(X)$. Then $A\subseteq\mathcal{P}(X)$ for some $X\in E$. Thus $A\subseteq\bigcup_{X\in E}X$ and $A\in\bigcup_{X\in E}\mathcal{P}(X)$ and we are done. Note that the reverse inclusion does not hold since we only have $A\subseteq\mathcal{P}(X)$ for some $X\in E$ as compared to the intersection of power sets. 
\end{proof}
\end{prp}

\subsection{Cartesian Products}
We now define the cartesian product of two sets, whose elements are ordered pairs. 

\begin{defn}{Cartesian Product}{} Let $A,B$ be sets. Define the Cartesian Product of $A$ and $B$ to be $$A\times B=\{(a,b)\;|\;a\in A, b\in B\}$$
\end{defn}

Clearly by definition a cartesian product gives rise to a set of ordered pairs. But the converse is also true, where a set of ordered pairs can give rise to a cartesian product. 

\begin{prp}{}{} Suppose that $R$ is a set of ordered pairs. Then there exists $A,B$ such that $R\subseteq A\times B$. 
\begin{proof}
Simply define $A=\{a\;|\;(a,b)\in R\}$ and $B=\{b\;|\;(a,b)\in R\}$. These sets in fact have names as we will see in the next definition. 
\end{proof}
\end{prp}

Readers should make sure that the predicate $(a,b)\in R$ is a valid construct in the language of set theory, just as a sanity check. \\
As promised, we give names to the sets defined in the proof above. 

Unfortunately these definition will be forgotten and rarely be used again. \\
We end the section with properties of the cartesian product when used in conjunction with other set operators. 

\begin{prp}{}{} Let $A,B,X,Y$ be sets. 
\begin{itemize}
\item $(A\cup B)\times X=(A\times X)\cup(B\times X)$
\item $(A\cap B)\times (X\cap Y)=(A\times X)\cap(B\times Y)$
\item $(A\setminus B)\times X=(A\times X)\setminus(B\times X)$
\end{itemize}
\begin{proof} Again just a practise of expansion into logic. 
\end{proof}
\end{prp}

\begin{axm}{The Axiom of Choice}{}\\
\end{axm}

\pagebreak
\section{Relations on a Set}
\subsection{Relations}
Relations appear naturally in the course of studying mathematics. Some simple relations that are used commonly include $=$, $\leq$ and $\geq$ and $<,>$. In fact, $\subset$ and $\subseteq$ are also relations. \\
More generally, relations are used to associate two elements of a set. This could be done because that they share similar properties or used for comparison. 

\begin{defn}{Relation}{} Let $X,Y$ be sets. A relation from $X$ to $Y$ is a subset $R\subseteq X\times Y$. 
\end{defn}

The definition of relations with ordered pairs seems unnatural especially when considering the usual relations like $\leq$ and $\geq$. In practise we will rarely think about relations set theoreticly. This is only meant for formalization into the language of set theory, which in turn is the basis of modern mathematics. 

\begin{defn}{Types of Relations}{} Let $R$ be a relation. We say that 
\begin{itemize}
\item $R$ is reflexive if $(x,x)\in R$ for all $x\in R$
\item $R$ is symmetric if $(x,y)\in R\implies (y,x)\in R$ for all $x,y\in R$
\item $R$ is transitive if $(x,y)\in R$ and $(y,z)\in R$ implies $(x,z)\in R$ for all $x,y,z\in R$
\item $R$ is anti-symmetric if $(x,y)\in R$ and $(y,x)\in R$ implies $x=y$. 
\end{itemize}
\end{defn}

Readers can check that while $=$ is an equivalence relation, $<,>$ only satisfies transitivity while $\leq,\geq$ satisfies reflexivity in addition to transitivity. \\

Finally, we have inverse relations which proves itself useful when dealing with inverse functions. 

\begin{defn}{Inverse Relations}{} Let $R$ be a relation from $A$ to $B$. Define the inverse relation to be $$R^{-1}=\{(b,a)\;|\;(a,b)\in R\}\subseteq B\times A$$
\end{defn}

Notice that here, every relation is guaranteed to have an inverse. But for function, additional requirements have to be satisfied in order for functions to be reversed. \\

\subsection{Partitions and Equivalence Relations}
The remainder of the section is mainly for exhibiting the relation between partitions and equivalence relations. This is often useful in the sense that whenever an equivalence relation appears, a partition will be possible from the set. \\
Firstly we define partitions. 

\begin{defn}{Partition}{} Let $X$ be a set. A partition of $X$ is a disjoint collection $E$ of subsets of $X$ such that
\begin{itemize}
\item $A,B\in E$ and $A\neq B$ implies $A\cap B=\emptyset$
\item $\bigcup_{A\in E}A=X$
\end{itemize}
\end{defn}

Although we have yet to define the order of a set (number of elements in a set), it is important to note that partitions does not mean that the number of elements in each partition is the same. 

\begin{defn}{}{} Let $X$ be a set. Let $R$ be a relation on $X$. We say that $R$ is an equivalence relation if the following are true. 
\begin{itemize}
\item $R$ is reflexive
\item $R$ is symmetric
\item $R$ is transitive
\end{itemize}
\end{defn}

\begin{defn}{Equivalence Class}{} Let $R$ be an equivalence relation on a set $X$. Denote $[x]=\{y\in X\;|\;(x,y)\in R\}$ the equivalence class of $x\in X$ and $X/R=\{[x]\;|\;x\in X\}$ the set of all equivalence classes. 
\end{defn}

Now comes the main theorem, it is split into two parts for readability. The proof is not particularly long but may take some time to digest and understand. 

\begin{thm}{}{} An equivalence relation $R$ on a set $X$ induces a partition on $X$. 
\begin{proof}
For every $x\in X$, $x\in x/R$ thus $\bigcup_{x\in X}x/R=X$. Now suppose that $z\in x/R\cap y/R$, then $(x,z)\in R$ and $(y,z)\in R$. By the symmetric property $(z,y)\in R$. By transitivity $(x,y)\in R$. Thus $x/R=y/R$. This proves that $X/R$ is a partition. 
\end{proof}
\end{thm}

\begin{thm}{}{} A partition on $X$ induces an equivalence relation $R$ on $X$. 
\begin{proof} Suppose that $X$ is partitioned. Define a relation $R$ to be $(x,y)\in R$ if and only if $x,y$ are in the same partition. \\

We now prove $R$ is an equivalence relation. We have that $(x,x)\in R$ for every $x$ since they necessarily appear in the same set and none others (by defition of partition) thus the reflexive property holds. If $(x,y)\in R$ then $x,y$ are in the same partition thus naturally $(y,x)\in R$ holds thus the symmetric property holds. Finally if $(x,y)\in R$ and $(y,z)\in R$ then $x,y,z$ are all in the same parition thus $(x,z)\in R$ holds which proves transitivity. We can now conclude that $R$ is an equivalence relation and we are done. 
\end{proof}
\end{thm}

\pagebreak
\section{Functions between Sets}
\subsection{Functions}
Functions play an integral role in all of mathematics. Therefore it is important to be able to express this concept in terms of set theoretic language. 
\begin{defn}{Functions}{} Let $X,Y$ be sets. A function from $X$ to $Y$ is a relation $f\subseteq X\times Y$ such that
\begin{itemize}
\item For all $x\in X$, there exists $y\in Y$ such that $(x,y)\in f$. 
\item For all $x\in X$, if $(x,y)\in f$ and $(x,z)\in f$, then $y=z$. 
\end{itemize}
In this case, we say that $X$ is the domain of $f$ and $Y$ is the codomain of $f$. We often write $f$ as $f:X\to Y$ to indicate the domain and codomain of $f$. 
\end{defn}

As one can see, functions are defined based on relations which is why the study of relations is also important. The additional rules the a relation has to satisfy in order to be a function is simply that all of $X$ must be associated to exactly one thing in $y$, not zero, not two, meaning everything in the domain must be linked to something in $Y$. \\

An immediate consequence is that since relations are subsets of the cartesian product, all functions from $X$ to $Y$ must be encapsulated by the cartesian product in some way. 

\begin{prp}{}{} The set of all functions from $X$ to $Y$ is a subset of $Y^X=\mathbb{P}(X\times Y)$. 
\begin{proof}{}{} Note that every function is a relation thus this induces a subset relation betweeen functions on a set and relations on a set. Then since we have shown that $R\subseteq X\times Y$, any function must be an element of $\mathbb{P}(X\times Y)$ and thus the set of all functions is a subset of $\mathbb{P}(X\times Y)$. 
\end{proof}
\end{prp}

Below we give three crucial functions which arises in most of the areas of mathematics. 

\begin{defn}{Inclusion Map}{} Let $X\subset Y$ and $f:X\to Y$ where $f$ is defined as $f(x)=x$. $f$ is called the inclusion map of $X$ into $Y$. 
\end{defn}

Notice the strict inclusion on $X\subset Y$. The inclusion map is meant to encorporate and identify $X$ inside of $Y$. This is most often used when we want to extend the domain of a function. When the strict inclusion is relaxed and we have $X=Y$, it is called the identity map. 

\begin{defn}{Identity Map}{} The inclusion map from $X$ to $X$ is called the identity map on $X$. 
\end{defn}

The name identity map will become clear once we reach inverse functions. 

\begin{defn}{Restriction Map}{} Let $f:Y\to Z$ and $X\subset Y$. The restriction map of $f$ is the function $g:X\to Z$ such that $g(x)=f(x)$ for all $x\in X$. Conversely, the extension map of $g\to Y$ is $f$. We write $g=f\;|\;X$. 
\end{defn}

Restriction maps are simply copies of the original map that is restricted to a certain subset of the original domain. \\

Finally, there are three important properties that a function can take. 

\begin{defn}{Bijective Functions}{} Let $f:X\to Y$ be a function. 
\begin{itemize}
\item $f$ is injective if $f(x_1)=f(x_2)\implies x_1=x_2$
\item $f$ is surjective if for all $y\in Y$ there exists $x\in X$ such that $f(x)=y$
\item $f$ is bijective if it is both injective and surjective
\end{itemize}
\end{defn}

This properties of a function does not only depend on how the function/relation is defined, but the domain and codomain also plays a part. 

\subsection{Compositions}
Functions are allowed to be composed. By doing this we are essentially creating a new function. 
\begin{defn}{Composition of Functions}{} Let $f:A\to B$ and $g:B\to C$ be two functions. Define the composition of $f$ and $g$ to be $$g\circ f:A\to C$$ If $a\in A$ then $$(g\circ f)(a)=g(f(a))$$
\end{defn}

Readers should verify that the new object $g\circ f$ is a function. 

\begin{lmm}{}{} Composition of functions result in a new function. 
\begin{proof}
Easy exercise. 
\end{proof}
\end{lmm}

While composition of functions is in general not commutative, it is fortunately associative. 

\begin{prp}{Associativity of Functions}{} Let $f:A\to B$, $g:B\to C$ and $h:C\to D$ be functions. Then the following is true. $$(h\circ g)\circ f=h\circ(g\circ f)$$
\begin{proof}
Simple manipulation of definition of composition. 
\end{proof}
\end{prp}

In general, composition preserves injectivity and surjectivity, as seen by the folllowing proposition. 

\begin{prp}{}{} Let $f:A\to B$ and $g:B\to C$ be functions. 
\begin{itemize}
\item If $f$ and $g$ are injective then $g\circ f$ is injective
\item If $f$ and $g$ are surjective then $g\circ f$ is surjective
\item If $f$ and $g$ are bijective then $g\circ f$ is bijective
\end{itemize}
\begin{proof}
Easy exercise involving the use of definition of injectivity and surjectivity. 
\end{proof}
\end{prp}

\subsection{Inverses}
Inverse functions serve the important role of inverting functions so that we know what element in the domain is mapped to a fixed element in the codomain. However the condition that the inverse exists must be studied. 

\begin{defn}{Inverse Functions}{} Let $f:X\to Y$ be a function. If the inverse relation $f^{-1}:Y\to X$ is also a function, then we say that $f^{-1}$ is the inverse function of $f$. 
\end{defn}

The main criterion for inversability of a function is given by the below characterization. 

\begin{thm}{}{} Let $f:X\to Y$ be a function. The inverse relation $f^{-1}$ is a function from $Y$ to $X$ if and only if $f$ is bijective. 
\begin{proof}
We first suppose that the inverse of $f$ is a function. We aim to prove injectivity and surjectivity. \\
Injectivity: Suppose that $f(x_1)=f(x_2)=y$. In terms of relations, this means that $(x_1,y)\in f$ and $(x_2,y)\in f$. By definition of inverse relations, $(y,x_1)\in f^{-1}$ and $(y,x_2)\in f^{-1}$. But since $f^{-1}$ is a function, $x_1=x_2$ and we are done. \\
Surjectivity: We want for every $y\in Y$ there exists $x\in X$ such that $f(x)=y$. So choose an arbitrary $y\in Y$. Since $f^{-1}$ is a function from $Y$ to $X$, $f^{-1}(y)=x$ lies in $X$. Then $(y,x)\in f^{-1}$ implies that $(x,y)\in f$, which we are done. \\

Finally, suppose now that $f$ is bijective. We aim to show that $f^{-1}$ is a function. There are two items to show: that for every $y\in Y$, there exists $x\in X$ such that $f^{-1}(y)=x$ and that $(y,x)\in f^{-1}$ and $(y,z)\in f^{-1}$ implies $x=z$. For the first item, we use the fact that $f$ is surjective. Let $y\in Y$. By surjectivity, there exists $x\in X$ such that $(x,y)\in f$. Then by definition of inverse relation $(y,x)\in f^{-1}$ and we are done. \\
Now for the second item, suppose that $(y,x)\in f^{-1}$ and $(y,z)\in f^{-1}$. Then by definition of inverse relation $(x,y)\in f$ and $(z,y)\in f$. Then using injectivity, we see that this should imply $x=z$ and so we are done. 
\end{proof}
\end{thm}

As seen in the proof, for $f^{-1}$ to be a function from $Y$ to $X$, injectivity and surjectivity plays a crucial role. \\
From the theorem, inverses of a function exists if and only if $f$ is bijective. We often call bijectivity a necessary and sufficient condition for inverses. Necessary here means that without this property, inverses would not exist. Sufficiency here means that with this property, inverses can exists. Both of which when used together, exactly means "if and only if". 

\begin{prp}{}{} If $f:X\to Y$ is a bijective function then $f^{-1}$ is bijective. Moreover, $f^{-1}\circ f$ is the identity function on $X$ and $f\circ f^{-1}$ is the identity function on $Y$. 
\begin{proof}
We know that since $f:X\to Y$ is bijective, $f^{-1}:Y\to X$ is a proper function. We first prove injectivity. Suppose that $(y,x)\in f^{-1}$ and $(z,x)\in f^{-1}$. By definition of inverse relation we have that $(x,y)\in f$ and $(x,z)\in f$. This means that $y=z$ by definition of a function. For surjectivity, suppose that $x\in X$. Since $f$ is a function from $X$, there exists $y$ such that $f(x)=y$. But this means that $(x,y)\in f$ and by definition of inverse relations, $(y,x)\in f^{-1}$ and so we are done. \\
Making sure that applying the inverse and the function itself is just the identity function is an easy exercise. 
\end{proof}
\end{prp}

\begin{defn}{Images and Preimages}{} Let $f:X\to Y$ be a function. Let $A\subseteq X$ and $B\subseteq Y$. Denote the image of $A$ under $f$ to be $$f(A)=\{y\in Y\;|\;f(x)=y,\forall x\in A\}\subseteq Y$$
Define the preimage of $B$ under $f$ to be the set $$f^{-1}(B)=\{x\in X\;|\;f(x)\in B\}\subseteq X$$
\end{defn}

This is such an abuse of notation that I cannot stress enough. Try not to be confused with the usual inverse of $f$, which does not always exists as a function, while the preimage, always exists regardless of whether $f$ has an inverse function. \\

Now that images and preimages have come into play, can you express surjectivity in terms of images and/or preimages? Can you also express the condition for bijecitivity and inverses in terms of images and/or preimages? \\

Next proposition is a crucial one because it tells us what happens by applying $f$ and its inverse relation when inverses of the function may not exist. 

\begin{prp}{}{} Let $A,B,X,Y$ be sets. Let $f:X\to Y$. 
\begin{itemize}
\item If $B\subseteq Y$ then $f(f^{-1}(B))\subseteq B$
\item If $B\subseteq Y$ and $f$ is surjective then $f(f^{-1}(B))=B$
\item If $A\subseteq X$ then $A\subseteq f^{-1}(f(A))$
\item If $A\subseteq X$ and $f$ is injective then $f^{-1}(f(A))=A$
\end{itemize} 
\begin{proof}
Let $f:X\to Y$ be a function. 
\begin{itemize}
\item Let $y\in f(f^{-1}(B))$. Then there exists $x\in f^{-1}(B)$ such that $y=f(x)$. But $x\in f^{-1}(B)$ implies $f(x)\in B$ by definition. Thus $y\in B$ and we are done. 
\item We just have to show that $B\subseteq f(f^{-1}(B))$. Let $f$ be surjective and $y\in B$. Then by surjectivity there exists $x\in f^{-1}(B)$ such that $y=f(x)$. But $x\in f^{-1}(B)$ means that $f(x)\in f(f^{-1}(B))$. Thus $y\in f(f^{-1}(B))$ and we are done. 
\item Let $x\in A$. Then $f(x)\in f(A)$. But by definition of $f^{-1}(f(A))$, $x\in f^{-1}(f(A))$ thus we are done. 
\item We just have to show that $f^{-1}(f(A))\subseteq A$. Let $f$ be injective and $x\in f^{-1}(f(A))$. Then by definition, $f(x)\in f(A)$. By injectivity, there exists only one element in $A$ that maps to $f(x)$, and that is precisely $x$. Thus $x\in A$ and we are done. 
\end{itemize}
\end{proof}
\end{prp}

Interested readers may look up left and right inverses of a function. They are characterized by the fourth and second item respecrtively. By combining these two properties, left and right inverses combine to become an inverse of a function in the sense that it maps $Y$ to $X$. \\

\pagebreak

\section{Number Systems}
\subsection{The Axiom of Infinity}
Before we formulate the natural numbers via set theoretic language, we need one more axiom to guarantee the existence of the set of natural numbers. 
\begin{defn}{Successor}{} Define the successor of a set $x$ to be $$x^+=x\cup\{x\}$$
\end{defn}

Notice that the successor of a set is also a set. With this notion we can define numbers as sets. For example, $0$ is simply the empty set $\emptyset$, $1$ would be $\{\emptyset\}$, $2$ would be $\{\emptyset,\{\emptyset\}\}$ and so on. This gives a unique code for every natural number, as well as giving order to the set of natural numbers, as we will see soon. \\

Finally, we need to guarantee that such a set exists. 

\begin{axm}{The Axiom of Infinity}{} There exists a set containing the empty set $\emptyset$ and containing the successor of each of its elements. 
\end{axm}

As with all the other axioms, to argue that an axiom is necessary and unprovable by other axioms is a very advanced topic. For now we will only state that it is needed. 

\subsection{The Peano The Axioms}
\begin{defn}{The Peano The Axioms}{} We say that $\omega$ is a successor set if
\begin{enumerate}
\item $\emptyset\in\omega$
\item $n\in\omega\implies n^+\in\omega$
\item $n^+\neq\emptyset$ for all $n\in\omega$
\item $n,m\in\omega$ and $n^+=m^+\implies n=m$
\item $S\subset\omega$ and $\emptyset\in S$ and $n^+\in S$ for all $n\in S$ implies $S=\omega$
\end{enumerate}
\end{defn}

Each of these axioms plays an important role in the formulation, without any one of them the natural numbers would not come into play. \\

The first item guarantees that the natural numbers is a non empty set. The second item guarantees that all successors, as required to define natural numbers, lie in the successor set. The third item guarantees that the natural numbers is not a huge loop of numbers that circulates back to $0$. The fourth item guarantees that no two numbers has a common successor. The final axiom prevents extra loops to appear other than the natural numbers itself. For example, there cannot be loops such as $y=x^+$, $z=y^+$ and $x=z^+$. Notice that the third item does not guarantees this since it only prevents the natural numbers to be one big loop. The fifth item in turn guarantees this since the natural numbers has to satisfy that when elements near the number is a natural number, it will also be a natural number. Since $x,y,z$ is a closed loop, they will never be natural numbers since the fifth item states the induction basis that starts from $0$. \\

From now on, in a successor set, we now say $0$ in place of $\emptyset$. If the readers wish to, we can now say that the successor of $0$ is $1$, the successor of $1$ is $2$ and vice versa. \\

The following theorem allows functions that work recursively to be defined. 

\begin{thm}{Recursion Theorem}{} Let $X$ be a set and $a\in X$. Let $f:X\to X$. There exists a function $u:\omega\to X$ such that
\begin{itemize}
\item $u(0)=a$
\item $u(n^+)=f(u(n))$ for all $n\in\omega$
\end{itemize}
\begin{proof} Let $$E=\{A\subset\omega\times X\;|\;(0,a)\in A\text{ and }(n,x)\in A\implies (n^+,f(x))\in A\}$$ Since $\omega\times X\in E$, $E\neq\emptyset$. Define $u=\bigcap_{B\in E}B$. Then $u\in E$. We want to show that $u$ is a function. We prove that the set of all $n$ such that $(n,x)\in u$ and $(n,y)\in u\implies x=y$ is $\omega$ Let $$S=\{n\in\omega\;|\;(n,x)\in u,(n,y)\in u\implies x=y\}$$ We prove it by the fifth item of Peano The Axiom. \\
We first show that $0\in S$. Suppose for a contradiction that $0\notin S$ and $(0,b)\in u$ and $a\neq b$. Consider $v=u-\{(0,b)\}$. $(0,a)\in v$ and $(n,x)\in A\implies (n^+,f(x))\in A$ since $n^+\neq 0$ for all $n\in\omega$. Thus $v\in E$ contradicts the fact that $u=\bigcap_{B\in E}B$. \\
We now show that $n^+\in S$ if $n\in S$. Let $n\in S$. Then there exists a unique $x\in X$ such that $(n,x)\in u$. Suppose that $n^+\notin S$. Then there exists $y\neq f(x)$ such that $(n,y)\in u$. Consider $v=u-\{(n,y)\}$. $(0,a)\in v$ and $(n,x)\in v\implies (n^+,f(x))\in v$. Thus $v\in E$ contradicts the fact that $u=\bigcap_{B\in E}B$. We thus have $S=\omega$, finishing the proof. 
\end{proof}
\end{thm}

Expanding things out, we see that $u(0)=a$, $u(1)=f(a)$, $u(2)=f(f(a))$ and so on. We have constructed a function $u$ such that input the number in $u$ means that you are compositing that number of $f$ to the initial element. This is why through this theorem, we allowed the existence of recursive functions. The application of this immediate as we will use it to define addition and multplication through this theorem. 


\subsection{Arithmetic}
We begin by defining the notion of addition in natural numbers. 
\begin{prp}{}{} For every natural number $m$ there exists a function $s_m:\mathbb{N}\to\mathbb{N}$ such that
\begin{itemize}
\item $s_m(0)=m$
\item $s_m(n^+)=(s_m(n))^+$
\end{itemize}
$s_m(n)$ is by definition, the sum $m+n$. 
\begin{proof}
Set $X$ as $\N$, $f$ as the successor function in recursion theorem and we are done. 
\end{proof}
\end{prp}

The recursion here used is the repeated use of successors, meaning we are applying $+1$ a certain amount of times. \\
We can now prove properties of addition in set theoretic language. 

\begin{prp}{Properties of Addition}{} Let $x,y,z\in\mathbb{N}$. 
\begin{itemize} 
\item (A1) $x+y\in\mathbb{N}$
\item (A2) $(x+y)+z=x+(y+z)$
\item (A3) $0+x=x=x+0$
\item (A4) $x+y=y+x$
\end{itemize}
\begin{proof}
\begin{itemize} We prove associativity, identity and commutativity in order. 
\item The closure under addition is direct from the definition of addition. 
\item For associativity, we induct on $z$. When $z=0$, we have 
\begin{align*}
(x+y)+0&=x+y \\
&=x+(y+0)
\end{align*}
Suppose that $(x+y)+n=x+(y+n)$, we have
\begin{align*}
(x+y)+n^+&=((x+y)+n)^+ \\
&=(x+(y+n))^+ \tag{Induction Hypothesis}\\
&=x+(y+n)^+ \\
&=x+(y+n^+)
\end{align*}
Thus by the principle of induction, we have associativity. 
\item For identity, we induct on $x$. When $x=0$, we have that
\begin{align*}
0+0=0=0+0
\end{align*}
Suppose that $0+n=n=n+0$, we have
\begin{align*}
0+n^+&=(0+n)^+ \\
&=n^+ \tag{Induction Hypothesis}\\
&=n^++0
\end{align*}
Thus by the principle of induction, we have identity. 
\item For commutativity, we induct on $y$ first to show that $x^++y=(x+y)^+$. When $y=0$, we have $x^++0=x^+=(x+0)^+$. Now suppose that $x^++n=(x+n)^+$
\begin{align*}
x^++n^+&=(x^++n)^+ \\
&=((x+n)^+)^+ \tag{Induction Hypothesis}\\
&=(x+n^+)^+
\end{align*}
Thus our first induction is complete. Now we prove commutativity by induction on $x$. When $x=0$, we have $0+y=y+0$ from identity. Now suppose that $x+y=y+x$. 
\begin{align*}
x^++y&=(x+y)^+ \tag{First induction}\\
&=(y+x)^+ \tag{Induction Hypothesis}\\
&=y+x^+
\end{align*}
Thus by the principle of induction, we have commutativity. 
\end{itemize}
\end{proof}
\end{prp}


We then proceed to multiplication. 

\begin{prp}{}{} For every natural number $m$ there exists a function $p_m:\mathbb{N}\to\mathbb{N}$ such that 
\begin{itemize}
\item $p_m(0)=0$
\item $p_m(n^+)=p_m(n)+m$
\end{itemize}
$p_m(n)$ is by definition, multiplication $m\times n$. 
\begin{proof}
Take $X$ as $\N$ and $f$ as $f(x)=x+m$. Then using the recursion theorem we are done. 
\end{proof}
\end{prp}

We note here, that the successor function $n^+$ is in fact equivalent to $n+1$ (using the definition of addition). This may be seen inherently when the successor notion is introduced, but it is only now that we can formulate it properly since addition is defined. \\
Similarly, the recursion here is that repeated addition of $+m$. And we can also prove remaining properties of multiplication in set theoretic language. 

\begin{prp}{}{} Let $x,y,z\in\mathbb{N}$. Addition and multiplication follow the distributive law $x\cdot(y+z)=x\cdot y+x\cdot z$. 
\begin{proof} We prove the distributive law by induction on $z$. When $z=0$, we have $x\cdot(y+0)=x\cdot y$ and $x\cdot y+x\cdot 0=x\cdot y$. Now suppose that $x\cdot(y+n)=x\cdot y+x\cdot n$. 
\begin{align*}
x(y+n^+)&=x(y+n)^+ \tag{Definition of Addition}\\
&=x(y+n)+x \tag{Definition of Multiplication}\\
&=(xy+xn)+x \tag{Induction Hypothesis}\\
&=xy+xn+x \tag{Associativity of Addition}\\
xy+xn^+&=xy+(xn+x) \tag{Definition of Multiplication}\\
&=xy+xn+x \tag{Associativity of Addition}
\end{align*}
Thus by the principle of induction, we have the distributive law. 
\end{proof}
\end{prp}


\begin{prp}{}{} Let $x,y,z\in\mathbb{N}$. 
\begin{itemize}
\item (M1) $x\cdot y\in\mathbb{N}$
\item (M2) $(x\cdot y)\cdot z=x\cdot(y\cdot z)$
\item (M3) $1\cdot x=x=x\cdot 1$
\item (M4) $x\cdot y=y\cdot x$
\end{itemize}
\begin{proof} We prove associativity, commutativity, identity in this order. Note we first prove commutativity then prove identity. 
\item The closure under Multiplication is direct from the definition of multiplication. 
\begin{itemize}
\item We prove associativity by induction on $z$. When $z=0$, $(x\cdot y)\cdot 0=0$ and $x\cdot(y\cdot 0)=x\cdot 0=0$. Now suppose that $(x\cdot y)\cdot n=x\cdot(y\cdot n)$. We have
\begin{align*}
(x\cdot y)\cdot n^+&=(x\cdot y)\cdot n+x\cdot y \tag{Definition of Multiplication}\\
&=x\cdot y+(x\cdot y)\cdot n \tag{Commutativity of Addition}\\
&=x\cdot y+x\cdot(y\cdot n) \tag{Induction Hypothesis}\\
&=x\cdot(y+y\cdot n) \tag{Distributivity}\\
&=x\cdot(y\cdot n+y) \tag{Commutativity of Addition}\\
&=x(y\cdot n^+) \tag{Definition of Multiplication}
\end{align*}
Thus by the principle of induction, we have the associative law. 
\item We prove commutativity by induction on $y$. When $y=0$, we have $x\cdot0=0=0\cdot x$. Now suppose that $x\cdot y=y\cdot x$, we have
\begin{align*}
x\cdot y^+&=(x\cdot y)+x \tag{Definition of Multiplication}\\
&=y\cdot x+x \tag{Induction Hypothesis}\\
&=x+\cdot(y+x) \tag{Commutativity of Addition}\\
&=y^+\cdot x \tag{Distributivity}
\end{align*}
Thus by the principle of induction, we have the commutative law. 
\item The identity is a special case of the commutative law, taking $y=1$. 
\end{itemize}
\end{proof}
\end{prp}

Now that we have the natural numbers, we can also extend the numbers into integers, rationals, real numbers and even complex numbers. Most of them without the use of set theoretic language. However, this is another topic unrelated to set theory mostly. 

\pagebreak
\section{Ordering}
\subsection{Total and Partial Orders}
\begin{defn}{Partial Order}{} Let $X$ be a set. Let $R$ be a relation on $X$. We say that $R$ is a partial order on $X$ if the following are true. 
\begin{itemize}
\item $R$ is reflexive
\item $R$ is anti-symmetric
\item $R$ is transitive
\end{itemize}
In this case, we say that $R$ is partially ordered, or that $R$ is a poset. 
\end{defn}

\begin{defn}{Total Order}{} Let $X$ be a set. Let $R$ be a relation on $X$. We say that $R$ is a total ordering on $X$ if for any $x,y\in X$, either $(x,y)\in R$ or $(y,x)\in R$. In this case, we say that $X$ is totally ordered. 
\end{defn}

\begin{defn}{Chains}{} Let $X$ be a set. Let $R$ be a partial order on $X$. A chain in $X$ is a subset $S\subseteq X$ such that $R$ restricted to $S$ gives a total order on $S$. 
\end{defn}

\begin{defn}{Initial Segments}{} Let $X$ be a partially ordered set and $a\in X$, the set $$s(a)=\{x\in X:x<a\}$$ is the initial segment determined by $a$. The weak initial segment is denoted $$\bar{s}(a)=\{x\in X:x\leq a\}$$ 
\end{defn}

\begin{defn}{Least and Greatest Element}{} Let $X$ be a partially ordered set and $a\in X$ such that $a\leq x$ for all $x\in X$. Then $a$ is the least element of $X$. If $b\in X$ such that $x\leq b$ for all $x\in X$ then $b$ is the greatest element of $X$. 
\end{defn}

\begin{defn}{Minimal and Maximal Elements}{} Let $X$ be a partially ordered set and $a\in X$ such that $x\leq a$ implies $x=a$, then $a$ is called the minimal element of $X$. If $b\in X$ such that $b\leq x$ implies $x=b$, then $b$ is called the maximal element of $X$. 
\end{defn}

\subsection{Ordering the Natural Numbers}
Another important aspect of the natural numbers is that they are comparable. We have the notion of size in them. The Peano axioms for the natural numbers also encapusulates this nicely. 

\begin{defn}{Comparable}{} Two natural numbers $m,n$ are comparable if either $m\in n$ or $m=n$ or $n\in m$. 
\end{defn}

This is called a trichotomy, which means that two natural numbers are comparable when exactly one out of the three conditions are fulfilled. Since we do not have the concept of size yet, we use belonging symbols because if one remembers, natural numbers are defined recursively. \\
The following theorem states that the trichotomy holds for any two natural numbers, which leads us to being able to compare them. 

\begin{thm}{}{} Any two natural numbers are comparable. 
\begin{proof}
\end{proof}
\end{thm}

Now that we have seen that any two natural numbers are comparable, we can essentially order them according to whether one is a subset of another, or in terms of magnitude, whether one is larger than the other or not. 

\begin{defn}{Order in $\N$}{} Define the relation $<$ for two natural numbers $m,n$ such that if $m\in n$, then $m<n$. 
\end{defn}

As we will see later, even comparisons have different types, namely total orders and partial orders. Total order means that everything in the set can be rearranged into one long queue according to the way we want to order it. Partial order means that not everything in the set is comparable against each other, leading to a tree like appearance when we try and sort the elements. 

\begin{prp}{}{} The relation $<$ on $\N$ is transitive. 
\end{prp}

It is worth noting here that $<$ is neither reflexive nor symmetric which the readers can check. 

\pagebreak
\section{Equivalent Formations of The Axiom of Choice}
\subsection{Zorn's Lemma}
\begin{defn}{Families}{} A family is a function $f:I\to X$ where $I$ is an index set, usually $\omega$ or a natural number, such that every element of the range of $f$ is of the form $x_i$, $i\in\omega$. 
\end{defn}

\begin{thm}{}{} If a set is infinite, then it has a subset equivalent to $\omega$. 
\end{thm}

\begin{thm}{Zorn's Lemma}{} If $X$ is a partially ordered set such that every chain in $X$ has an upper bound, then $X$ contains a maximal element. 
\end{thm}

\subsection{The Well Ordering Principle}
\begin{defn}{Well Ordered Set}{} A partially ordered set is well ordered if every non-empty subset of it has a smallest element. 
\end{defn}

\begin{thm}{}{} Every well ordered set is totally ordered. 
\end{thm}

\begin{thm}{The Principle of Transfinite Induction}{} Suppose that $S$ is a subset of a well ordered set $X$, and suppose that $x\in X$ such that $s(x)\subset S$, then $x\in S$. 
\end{thm}

\begin{defn}{Continuation}{} A well ordered set $A$ is a continuation of a well ordered set $B$ if
\begin{itemize}
\item $B\subset A$
\item $B$ is an initial segment of $A$
\item $B$ and $A$ have the same ordering
\end{itemize}
\end{defn}

\begin{thm}{}{} If $E$ is an arbitrary collection of initial segment of a well ordered set, $E$ is a chain with respect to continuation. 
\end{thm}

\begin{thm}{}{} If a collection $E$ of well ordered sets is a chain with respect to continuation and if $U=\bigcup_{X\in E}X$, then there is a unique well ordering of $U$ such that $U$ is a continuation of each set. 
\end{thm}

\begin{thm}{Well Ordering Theorem}{} Every set can be well ordered. 
\end{thm}

\begin{prp}{}{} The well ordering theorem implies the axiom of choice. 
\end{prp}

\subsection{Transfinite Recursion}
\begin{defn}{A sequence of type $a$ in $X$}{} Let $a$ be an element in a well ordered set $W$. Let $X$ be an arbitrary set. The sequence of type $a$ in $X$ means a function from $s(a)\subset W$ into $X$. 
\end{defn}

\begin{defn}{A sequence of type $W$ in $X$}{} A sequence of type $W$ in $X$ is a function $f$ whose domain consists of all sequences of type $a$ in $X$, for all elements $a$ in $W$ and range is included in $X$. 
\end{defn}

\begin{thm}{Transfinite Recursion Theorem}{} If $W$ is a well ordered set and if $f$ is a sequence function of type $W$ in a set $X$, then there exists a unique function $U$ from $W$ into $X$ such that $U(a)=f(U^a)$ for each $a$ in $W$, where $U^a$ is the restriction of $U:W\to X$ to the initial segment $s(a)$. 
\end{thm}

\begin{defn}{Similarity}{} Two partially ordered sets are similar if there is a one to one correspondence that preserves order, or $f(a)\leq f(b)\implies a\leq b$. 
\end{defn}

\begin{prp}{}{} Let $f$ be a similarity from $X$ to $Y$. 
\begin{itemize}
\item $f^{-1}$ is a similarity from $Y$ to $X$
\item $gf$ is a similarity from $X$ to $Z$ if $g$ is a similarity. 
\end{itemize}
\end{prp}

\begin{thm}{}{} If $f$ is a similarity of a well ordered set $X$ to itself, then $a\leq f(a)$ for all $a\in X$. 
\end{thm}

\begin{thm}{}{} Let $X,Y$ be well ordered sets. If $X$ and $Y$ are similar, then the correspondence function is unique. 
\end{thm}

\begin{thm}{}{} A well ordered set is never similar to one of its initial segments. 
\end{thm}

\begin{thm}{Compatibility Theorem}{} Let $X$ and $Y$ be well ordered sets. Either $X$ and $Y$ are similar or one of them is similar to an initial segment of the other. 
\end{thm}

\pagebreak
\section{Counting Beyond Infinity}
\subsection{Ordinal Numbers}

\subsection{Cardinality of a Set}
\begin{defn}{Cardinality of a Set}{} Let $X$ be a set. Define the cardinality $\abs{X}$ of $X$ to be the smallest ordinal number $\alpha$ such that $X$ and $\alpha$ are bijective. 
\end{defn}

For example, if $A=\{a,b,c,d\}$, then it has cardinality $4$ and we write it as $\abs{A}=4$. From the finiteness of the sets, we can perform the usual addition and multiplication on cardinality, provided it makes sense. 

\begin{prp}{}{} Let $X,Y$ be sets. Then $\abs{X}\leq\abs{Y}$ if and only if there exists an injection $X\to Y$. 
\end{prp}

\begin{prp}{}{} Let $X,Y$ be sets. Then $\abs{X}=\abs{Y}$ if and only if there exists a bijection $X\to Y$. 
\end{prp}

\begin{prp}{Cantor's Diagonality Argument}{} Let $X$ be a set. Then $\abs{X}<\abs{\mP(X)}$. 
\end{prp}

\begin{defn}{Finite Sets}{} Let $X$ be a set. We say that $X$ is finite if $\abs{X}\in\N$. 
\end{defn}

\begin{lmm}{}{} Let $X$ be a set. Let $n\in\N$. Then $X$ contains $n$ elements if and only if $\abs{X}=n$. 
\end{lmm}

\begin{prp}{}{} Let $E,F$ be sets with finite cardinality. 
\begin{itemize}
\item If $E,F$ are disjoint, then $\abs{E\cup F}=\abs{E}+\abs{F}$
\item $\abs{E\times F}=\abs{E}\cdot\abs{F}$
\end{itemize}
\end{prp}

\begin{defn}{Countably Infinite Sets}{} We say that a set $A$ is countably infinite if it has cardinality equal to $\N$. In other words, if $$\abs{A}=\abs{\N}$$
\end{defn}

In particular, mathematicians also say that a set is countable if it is either finite or countably infinite. This is due to the fact that there is also a notion of uncountability. 

\begin{defn}{Uncountable Sets}{} We say that a set $A$ is uncountable if it has cardinality strictly greater than $\N$. In other words, if $$\abs{A}>\abs{\N}$$
\end{defn}

\subsection{Cardinal Numbers}
\begin{defn}{Cardinal Numbers}{} A cardinal number is an ordinal number $\kappa$ of the form $\abs{X}$ for some set $X$. 
\end{defn}

\begin{defn}{Finite Cardinals}{} Let $\kappa$ be a cardinal number. We say that $\kappa$ is finite if it has the cardinality of a finite set. 
\end{defn}
 
\end{document}