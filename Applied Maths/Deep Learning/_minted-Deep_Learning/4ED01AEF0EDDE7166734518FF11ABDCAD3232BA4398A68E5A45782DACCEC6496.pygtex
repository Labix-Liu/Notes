\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k}{def} \PYG{n+nf}{update\PYGZus{}parameters}\PYG{p}{(}\PYG{n}{params}\PYG{p}{,} \PYG{n}{grads}\PYG{p}{,} \PYG{n}{learning\PYGZus{}rate}\PYG{p}{):}

    \PYG{n}{parameters} \PYG{o}{=} \PYG{n}{copy}\PYG{o}{.}\PYG{n}{deepcopy}\PYG{p}{(}\PYG{n}{params}\PYG{p}{)}
    \PYG{n}{L} \PYG{o}{=} \PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{parameters}\PYG{p}{)} \PYG{o}{//} \PYG{l+m+mi}{2} \PYG{c+c1}{\PYGZsh{} number of layers in the neural network}

    \PYG{k}{for} \PYG{n}{l} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{L}\PYG{p}{):}
        \PYG{n}{parameters}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}W\PYGZdq{}} \PYG{o}{+} \PYG{n+nb}{str}\PYG{p}{(}\PYG{n}{l}\PYG{o}{+}\PYG{l+m+mi}{1}\PYG{p}{)]} \PYG{o}{=} \PYG{n}{params}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}W\PYGZdq{}} \PYG{o}{+} \PYG{n+nb}{str}\PYG{p}{(}\PYG{n}{l}\PYG{o}{+}\PYG{l+m+mi}{1}\PYG{p}{)]}\PYG{o}{\PYGZhy{}}\PYG{n}{learning\PYGZus{}rate}\PYG{o}{*}\PYG{n}{grads}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}dW\PYGZdq{}} \PYG{o}{+} \PYG{n+nb}{str}\PYG{p}{(}\PYG{n}{l}\PYG{o}{+}\PYG{l+m+mi}{1}\PYG{p}{)]}
        \PYG{n}{parameters}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}b\PYGZdq{}} \PYG{o}{+} \PYG{n+nb}{str}\PYG{p}{(}\PYG{n}{l}\PYG{o}{+}\PYG{l+m+mi}{1}\PYG{p}{)]} \PYG{o}{=} \PYG{n}{params}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}b\PYGZdq{}} \PYG{o}{+} \PYG{n+nb}{str}\PYG{p}{(}\PYG{n}{l}\PYG{o}{+}\PYG{l+m+mi}{1}\PYG{p}{)]}\PYG{o}{\PYGZhy{}}\PYG{n}{learning\PYGZus{}rate}\PYG{o}{*}\PYG{n}{grads}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}db\PYGZdq{}} \PYG{o}{+} \PYG{n+nb}{str}\PYG{p}{(}\PYG{n}{l}\PYG{o}{+}\PYG{l+m+mi}{1}\PYG{p}{)]}

    \PYG{k}{return} \PYG{n}{parameters}
\end{Verbatim}
